{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import copy\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history/history-merge-date_5-18-14-40.pkl\", \"rb\") as handle:\n",
    "    history = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, title=\"Model Loss\"):\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history, \"Merge-Concat Model Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history/history-inject-date_5-16-15-45.pkl\", \"rb\") as handle:\n",
    "    history2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history2, \"Inject Model Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history/history-merge_add-date_6-4-14-11.pkl\", \"rb\") as handle:\n",
    "    history3 = pickle.load(handle)\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history3, \"Merge-Add Model Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/tokenizer/tokenizer.pkl\",\"rb\") as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1 + len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_tokenizer = {index: word for word,index in tokenizer.word_index.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/features/valid_features.pkl\", \"rb\") as handle:\n",
    "    valid_features = pickle.load(handle)\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = []\n",
    "for k in valid_features:\n",
    "    valid_ids.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo_features(photo_id):\n",
    "    return valid_features[photo_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model1 = load_model(\"models/model_merge-date_5-18-14-40-ep016-loss4.704_lr-0.010000_patience-3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model(\"models/model_inject-date_5-16-15-45-ep030-loss5.009_lr-0.010000_patience-3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_id(photo_id, model, tokenizer, reverse_tokenizer, max_length = 15):\n",
    "    photo_features = get_photo_features(photo_id)\n",
    " \n",
    "    in_seq = np.repeat(0, max_length)\n",
    "    in_seq[0] = tokenizer.word_index[\"startseq\"]\n",
    "\n",
    "    end_token = tokenizer.word_index[\"endseq\"]\n",
    "    for i in range(1, max_length):\n",
    " \n",
    "        pred = model.predict([photo_features,in_seq.reshape(1,-1)], verbose=0)\n",
    "\n",
    "        pred = np.argmax(pred)\n",
    "        in_seq[i] = pred\n",
    "\n",
    "        if pred == end_token:\n",
    "            break\n",
    "\n",
    "    out_seq = in_seq[1:]\n",
    "\n",
    "    out_string = []\n",
    "    for idx in out_seq:\n",
    "        if idx == 0 or idx == end_token:\n",
    "            break\n",
    "        out_string.append(reverse_tokenizer[idx])\n",
    "    return(\" \".join(out_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[.9**i for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceCandidate(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def template_seq(start_idx = 1, max_length = 15, ignore_idx = None, alpha = .9):\n",
    "        seq = np.repeat(0,15)\n",
    "        seq[0] = start_idx\n",
    "\n",
    "        probs = np.repeat(0.0,15)\n",
    "        probs[0] = 1\n",
    "        return SequenceCandidate(seq, probs, max_length, ignore_idx, alpha)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __init__(self, seq, probs, max_length = 15, ignore_idx = None, alpha = .9):\n",
    "        assert len(seq) == max_length\n",
    "        self._max_length = max_length\n",
    "        self._seq = seq\n",
    "        self._probs = probs\n",
    "       \n",
    "        self._num_elem = max_length \n",
    "        for i in range(len(seq)):\n",
    "            if seq[i] == 0:\n",
    "                self._num_elem = i  \n",
    "                break\n",
    "        \n",
    "        self._bigrams = set()\n",
    "        self._ignore_idx = ignore_idx\n",
    "        if ignore_idx is None:\n",
    "            self._ignore_idx = []\n",
    "        self._prob_weights = [alpha**i for i in range(max_length)]\n",
    "    \n",
    "    \n",
    "    def add_token(self, token, prob):\n",
    "       \n",
    "        if self._num_elem >= self._max_length:\n",
    "            raise IndexError(\"Sequence is already populated.\\nCan't add any more tokens to it.\")\n",
    "        \n",
    "        newcandidate = copy.deepcopy(self)\n",
    "      \n",
    "        newcandidate._seq[self._num_elem] = token\n",
    "        \n",
    "        newcandidate._probs[self._num_elem] = prob\n",
    "        \n",
    "        newcandidate._bigrams.add(tuple(newcandidate._seq[self._num_elem - 1 : newcandidate._num_elem + 1]))\n",
    "    \n",
    "        newcandidate._num_elem += 1\n",
    "        return(newcandidate)\n",
    "    \n",
    "    def probsum(self):\n",
    "        \n",
    "        valid_probs = self._probs[~np.in1d(self._seq, self._ignore_idx)]\n",
    "        \n",
    "        return np.sum(np.multiply(valid_probs, self._prob_weights[:len(valid_probs)]))\n",
    "    \n",
    "    def final_token(self):\n",
    "        return self._seq[self._num_elem - 1]\n",
    "    \n",
    "    \n",
    "    def to_words(self,reverse_tokenizer, end_idx):\n",
    "        \n",
    "        out_words = []\n",
    "        for i in range(1,len(self._seq)):\n",
    "            \n",
    "            idx = self._seq[i]\n",
    "            if idx == 0 or idx == end_idx:\n",
    "                break\n",
    "            if idx in self._ignore_idx:\n",
    "                continue\n",
    "            \n",
    "            if self._seq[i - 1] != idx:\n",
    "                out_words.append(reverse_tokenizer[idx])\n",
    "        out_string = \" \".join(out_words)\n",
    "        return out_string\n",
    "    \n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        try:\n",
    "            return self.probsum() < other.probsum()\n",
    "        except AttributeError:\n",
    "            return NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_beam_id(photo_id, model,reverse_tokenizer, width, num_neighbors,\n",
    "                                 top_n = 3, end_idx = 2, max_length = 15, ignore_idx = [4], alpha = .9):\n",
    "    \n",
    "    photo_features = get_photo_features(photo_id)\n",
    "    \n",
    "    accepted_sequences = []\n",
    "    \n",
    "    population = []\n",
    "    \n",
    "    start_sequence = SequenceCandidate.template_seq(ignore_idx = ignore_idx, alpha = alpha)\n",
    "    population.append(start_sequence)\n",
    "    for i in range(max_length - 1):\n",
    "        tmp = []\n",
    "        for cand_seq in population:\n",
    "             \n",
    "            pred = model.predict([photo_features, cand_seq._seq.reshape(1,-1)], verbose=0)[0]\n",
    "            \n",
    "            pred_argsort = pred.argsort()\n",
    "            \n",
    "            for next_idx in pred_argsort[-num_neighbors:]:\n",
    "                \n",
    "                if (cand_seq.final_token(), next_idx) in cand_seq._bigrams:\n",
    "                    accepted_sequences.append(cand_seq)\n",
    "                    continue\n",
    "                \n",
    "                next_prob = pred[next_idx]\n",
    "                new_candidate = cand_seq.add_token(next_idx,next_prob)\n",
    "                \n",
    "                if next_idx == end_idx:\n",
    "                    accepted_sequences.append(new_candidate)\n",
    "                else:\n",
    "                    tmp.append(new_candidate)\n",
    "         \n",
    "        try:\n",
    "            population = sorted(tmp)[-width:]\n",
    "        except:\n",
    "            \n",
    "            population = tmp\n",
    "            break\n",
    "    \n",
    "    accepted_sequences = sorted(accepted_sequences + population, reverse = True)\n",
    "    \n",
    "    accepted = 0\n",
    "    outputwords, outputprobs = [], []\n",
    "    for acc_seq in accepted_sequences:\n",
    "        seq_string = acc_seq.to_words(reverse_tokenizer,end_idx)\n",
    "        if seq_string not in outputwords:\n",
    "            outputwords.append(seq_string)\n",
    "            outputprobs.append(acc_seq.probsum())\n",
    "            accepted += 1\n",
    "            if accepted >= top_n:\n",
    "                break\n",
    "    output = list(zip(outputwords, outputprobs))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../data/yelp_photos/photos/q82QFxvqPecnz8FWv_TxCw.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions_beam_id(\"q82QFxvqPecnz8FWv_TxCw\", model2, reverse_tokenizer, width = 5,\n",
    "                             num_neighbors=3, top_n = 3, ignore_idx = [4,61,345], alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions_beam_id(\"q82QFxvqPecnz8FWv_TxCw\", model2, reverse_tokenizer, width = 5,\n",
    "                             num_neighbors=3, top_n = 3, ignore_idx = [4,61,345], alpha = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions_beam_id(\"q82QFxvqPecnz8FWv_TxCw\", model2, reverse_tokenizer, width = 5,\n",
    "                             num_neighbors=3, top_n = 3, ignore_idx = [4,61,345], alpha = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../data/yelp_photos/photos/L5E4Qa0N5tPslTbxgVA7Gg.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions_beam_id(\"L5E4Qa0N5tPslTbxgVA7Gg\", model2, reverse_tokenizer, width = 5,\n",
    "                             num_neighbors=3, top_n = 3, ignore_idx = [4,61,345], alpha = .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions_beam_id(\"L5E4Qa0N5tPslTbxgVA7Gg\", model2, reverse_tokenizer, width = 5,\n",
    "                             num_neighbors=3, top_n = 3, ignore_idx = [4,61,345], alpha = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions_beam_id(\"L5E4Qa0N5tPslTbxgVA7Gg\", model2, reverse_tokenizer, width = 5,\n",
    "                             num_neighbors=3, top_n = 3, ignore_idx = [4,61,345], alpha = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(zip([1,2],[2,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions_beam_id(\"xd3WPCnSnaF4WvOK5X5kdQ\", model2, reverse_tokenizer, width = 5, num_neighbors=3, alpha =1.5, top_n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_photos(ids, model1, alpha1, alpha2, folder = \"examples/\"):\n",
    "    for photo_id in ids:\n",
    "        im1 = Image.open(\"../data/yelp_photos/photos/%s.jpg\"%photo_id)\n",
    "        descs1 = generate_predictions_beam_id(photo_id, model1, \n",
    "                    reverse_tokenizer, width = 5, num_neighbors=3,  top_n = 3,\n",
    "                                             ignore_idx = [4,61,345], alpha = alpha1)\n",
    "        draw = ImageDraw.Draw(im1)\n",
    "        for i in range(len(descs1)):\n",
    "            draw.text((0,i*10),str(descs1[i])[1:-1],(255,0,0))\n",
    "        \n",
    "        im2 = Image.open(\"../data/yelp_photos/photos/%s.jpg\"%photo_id)\n",
    "        descs2 = generate_predictions_beam_id(photo_id, model1, \n",
    "                    reverse_tokenizer, width = 5, num_neighbors=3,  top_n = 3,\n",
    "                                             ignore_idx = [4,61,345], alpha = alpha2)\n",
    "        draw = ImageDraw.Draw(im2)\n",
    "        for i in range(len(descs2)):\n",
    "            draw.text((0,i*10),str(descs2[i])[1:-1],(255,0,0))\n",
    "        \n",
    "        \n",
    "        total_width = im1.size[0] + im2.size[0]\n",
    "        max_height = max(im1.size[1] , im2.size[1])\n",
    "        new_im = Image.new('RGB', (total_width, max_height))\n",
    "        x_offset = 0\n",
    "        for im in [im1,im2]:\n",
    "            new_im.paste(im, (x_offset,0))\n",
    "            x_offset += im.size[0]\n",
    "        \n",
    "        new_im.save(\"%s%s.jpg\"%(folder,photo_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_dir = \"../data/yelp_photos/photos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../data/yelp_photos/photos/To6WAH5Rtok5ORBLyopnAw.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = generate_predictions_beam_id(\"To6WAH5Rtok5ORBLyopnAw\",\n",
    "                                     model1, reverse_tokenizer, width = 5, num_neighbors=3, alpha =1.5, top_n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(im)\n",
    "\n",
    "draw.text((0, 0),str(descs[0])[1:-1],(255,0,0))\n",
    "draw.text((0, 10),str(descs[1])[1:-1],(255,0,0))\n",
    "draw.text((0, 20),str(descs[2])[1:-1],(255,0,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(80)\n",
    "choices = np.random.choice(valid_ids, 100)\n",
    "choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir alpha7vs8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir alpha6vs7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_photos(choices,model2,alpha1 = .6, alpha2 = .7, folder = \"alpha6vs7/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_photos(ids, model1, alpha1, alpha2, folder = \"examples/\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [Image.open(photo_dir + c + \".jpg\") for c in choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(choices)):\n",
    "    desc = generate_predictions_id(choices[i], model = model, \n",
    "                               tokenizer = tokenizer, reverse_tokenizer = reverse_tokenizer)\n",
    "    im = all_images[i]\n",
    "    draw = ImageDraw.Draw(im)\n",
    "  \n",
    "    draw.text((0, 0),desc,(255,255,255))\n",
    "    im.save(\"/Users/timibennatan/Desktop/funny_images/%s.png\"%(choices[i]), \"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../data/yelp_photos/photos/J4kY0vanHHvkjpim7vr8nA.jpg\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../data/yelp_photos/photos/J4kY0vanHHvkjpim7vr8nA.jpg\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/J4kY0vanHHvkjpim7vr8nA.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../data/yelp_photos/photos/J4kY0vanHHvkjpim7vr8nA.jpg\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/795n_ZFZFum0R6IMXv4iow.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/YSixHEXmKUt47ws43y1ckA.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/HZ9M0E7e3MkGVqsWay9MJQ.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/N8cpFCz6XnkcWZ_vvuzHUg.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/GIj4ab48r_rHqdMHtPfEwQ.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/f6PktcNbaBU5XJdDmwsuBA.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/FmCbppb6mM73ZkTtVYQAZA.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/c5svSfbZTSEi5F8fv4n3og.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/DVU9SwtVRfpDGvTwJiKo-Q.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/f_tVArgZQ7941ggF3Rvt6A.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/FCkWALul8LBRMQppYq8tvg.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/q1jtcgo0j-ukiO1ANHkgGg.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/bkbfhk_tn4NtiiCDbgLWqg.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/tcpjFKWdLrHzzUujORqsEQ.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/iGefVUYU9dq5WC7yGjanJg.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/4ug7V8ep_SsNfFzuZi4pGw.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/SXVZ2eNglIexXlETW3_WNw.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/l3X2RU4K9So7zpRPyE47Og.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/0WEM3KzBtwBq21232FDDwQ.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/fXfqzKdLWyLTFWk4sJ7HkQ.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/AWHas5jH6AlHLZ78LoLL-w.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/Y8P-q4UUfzJaoEDo6_Zerg.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/bb2poXMhUXW2bRK0jjosHw.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../data/yelp_photos/photos/O4C7riqw83InALQEF50GoQ.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}