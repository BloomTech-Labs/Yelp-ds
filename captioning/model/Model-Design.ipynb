{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, RepeatVector, TimeDistributed, Merge, Masking\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(path):\n",
    "    with open(path, \"rb\") as handle:\n",
    "        arr = np.load(handle)\n",
    "    handle.close()\n",
    "    return (arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_photos = load_npy(\"../data/preprocessed/X_train_photos.npy\")\n",
    "X_train_captions = load_npy(\"../data/preprocessed/X_train_captions.npy\")\n",
    "embedding_matrix = load_npy(\"../data/embedding_matrix/embedding_matrix.npy\")\n",
    "y_train = load_npy(\"../data/preprocessed/y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_photos.shape)\n",
    "print(X_train_captions.shape)\n",
    "print(y_train.shape)\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_photo = Input(shape = (4096,), name=\"Inputs-photo\")\n",
    "drop1 = Dropout(0.5)(inputs_photo)\n",
    "dense1 = Dense(256, activation='relu')(drop1)\n",
    "inputs_caption = Input(shape=(15,), name = \"Inputs-caption\")\n",
    "embedding = Embedding(VOCAB_SIZE, 300,\n",
    "                mask_zero = True, trainable = False,\n",
    "                weights=[embedding_matrix])(inputs_caption)\n",
    "drop2 = Dropout(0.5)(embedding)\n",
    "lstm1 = LSTM(256)(drop2)\n",
    "\n",
    "merged = concatenate([dense1, lstm1])\n",
    "dense2 = Dense(256, activation='relu')(merged)\n",
    "outputs = Dense(VOCAB_SIZE, activation='softmax')(dense2)\n",
    "\n",
    "model = Model(inputs=[inputs_photo, inputs_caption], outputs=outputs)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='images/model1.png', show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/model1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit([X_train_photos,X_train_captions], to_categorical(y_train, VOCAB_SIZE), epochs = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_photo = Input(shape = (4096,), name=\"Inputs-photo\")\n",
    "drop1 = Dropout(0.5)(inputs_photo)\n",
    "dense1 = Dense(300, activation='relu')(drop1)\n",
    "cnn_feats = Masking()(RepeatVector(1)(dense1))\n",
    "inputs_caption = Input(shape=(15,), name = \"Inputs-caption\")\n",
    "embedding = Embedding(VOCAB_SIZE, 300,\n",
    "                mask_zero = True, trainable = False,\n",
    "                weights=[embedding_matrix])(inputs_caption)\n",
    "merged = concatenate([cnn_feats, embedding], axis=1)\n",
    "lstm_layer = LSTM(units=300,\n",
    "                  input_shape=(15 + 1, 300),   \n",
    "                  return_sequences=False,\n",
    "                  dropout=.5)(merged)\n",
    "\n",
    "\n",
    "outputs = Dense(units=VOCAB_SIZE,activation='softmax')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=[inputs_photo, inputs_caption], outputs=outputs)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd)\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='images/model6.png', show_shapes=True,show_layer_names=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/model6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X_train_photos,X_train_captions], y_train, epochs = 1, verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}