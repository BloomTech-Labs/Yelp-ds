{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.55.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_estimator = TensorFlow(source_dir='train_script',\n",
    "                             entry_point='launcher.sh',\n",
    "                             model_dir = '/opt/ml/model',\n",
    "                             train_instance_type='ml.g4dn.12xlarge',\n",
    "                             train_volume_size=20,\n",
    "                             train_instance_count=1,\n",
    "                             role=role,\n",
    "                             base_job_name='distilbert-regression',\n",
    "                             framework_version='2.1.0',\n",
    "                             py_version=\"py3\",\n",
    "                             script_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'train': 's3://yelp-dataset-pt-9/spencer/data/sentiment/en/ktrain/regression/trn.p',\n",
    "    'test': 's3://yelp-dataset-pt-9/spencer/data/sentiment/en/ktrain/regression/val.p',\n",
    "    'preproc': 's3://yelp-dataset-pt-9/spencer/data/sentiment/en/ktrain/regression/preproc.p'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-13 05:41:06 Starting - Starting the training job...\n",
      "2020-06-13 05:41:09 Starting - Launching requested ML instances.........\n",
      "2020-06-13 05:42:51 Starting - Preparing the instances for training......\n",
      "2020-06-13 05:43:46 Downloading - Downloading input data...\n",
      "2020-06-13 05:44:37 Training - Downloading the training image.....\u001b[34m2020-06-13 05:45:16,845 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-06-13 05:45:17,323 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"preproc\": \"/opt/ml/input/data/preproc\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/ml/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"preproc\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"distilbert-regression-2020-06-13-05-41-06-276\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-652081700929/distilbert-regression-2020-06-13-05-41-06-276/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"launcher.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"launcher.sh\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/ml/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=launcher.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"preproc\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"preproc\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=launcher.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-652081700929/distilbert-regression-2020-06-13-05-41-06-276/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"preproc\":\"/opt/ml/input/data/preproc\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"preproc\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"distilbert-regression-2020-06-13-05-41-06-276\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-652081700929/distilbert-regression-2020-06-13-05-41-06-276/source/sourcedir.tar.gz\",\"module_name\":\"launcher.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"launcher.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/ml/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_PREPROC=/opt/ml/input/data/preproc\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/bin/sh -c ./launcher.sh --model_dir /opt/ml/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mCollecting ktrain\n",
      "  Downloading ktrain-0.16.3.tar.gz (25.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.1.0\n",
      "  Downloading tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8 MB)\u001b[0m\n",
      "\n",
      "2020-06-13 05:45:12 Training - Training image download completed. Training in progress.\u001b[34mCollecting scikit-learn==0.21.3\n",
      "  Downloading scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7 MB)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib>=3.0.0\n",
      "  Downloading matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain->-r requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[34mCollecting fastprogress>=0.1.21\n",
      "  Downloading fastprogress-0.2.3-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras_bert>=0.81.0\n",
      "  Downloading keras-bert-0.84.0.tar.gz (27 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain->-r requirements.txt (line 1)) (2.22.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain->-r requirements.txt (line 1)) (0.14.1)\u001b[0m\n",
      "\u001b[34mCollecting langdetect\n",
      "  Downloading langdetect-1.0.8.tar.gz (981 kB)\u001b[0m\n",
      "\u001b[34mCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting cchardet==2.1.5\n",
      "  Downloading cchardet-2.1.5-cp36-cp36m-manylinux1_x86_64.whl (241 kB)\u001b[0m\n",
      "\u001b[34mCollecting networkx>=2.3\n",
      "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting bokeh\n",
      "  Downloading bokeh-2.0.2.tar.gz (8.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting seqeval\n",
      "  Downloading seqeval-0.0.12.tar.gz (21 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain->-r requirements.txt (line 1)) (20.3)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-3.1.0-py3-none-any.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting transformers>=2.11.0\n",
      "  Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\u001b[0m\n",
      "\u001b[34mCollecting ipython\n",
      "  Downloading ipython-7.15.0-py3-none-any.whl (783 kB)\u001b[0m\n",
      "\u001b[34mCollecting syntok\n",
      "  Downloading syntok-1.3.1.tar.gz (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (0.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (0.34.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (0.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (0.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (3.11.3)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain->-r requirements.txt (line 1)) (2019.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert>=0.81.0->ktrain->-r requirements.txt (line 1)) (2.3.1)\u001b[0m\n",
      "\u001b[34mCollecting keras-transformer>=0.37.0\n",
      "  Downloading keras-transformer-0.37.0.tar.gz (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain->-r requirements.txt (line 1)) (1.25.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain->-r requirements.txt (line 1)) (2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain->-r requirements.txt (line 1)) (2020.4.5.1)\u001b[0m\n",
      "\u001b[34mCollecting decorator>=4.3.0\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain->-r requirements.txt (line 1)) (5.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain->-r requirements.txt (line 1)) (2.11.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain->-r requirements.txt (line 1)) (7.0.0)\u001b[0m\n",
      "\u001b[34mCollecting tornado>=5\n",
      "  Downloading tornado-6.0.4.tar.gz (496 kB)\u001b[0m\n",
      "\u001b[34mCollecting typing_extensions>=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.2-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.22.2-py2.py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mCollecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm\n",
      "  Downloading tqdm-4.46.1-py2.py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mCollecting dill\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\u001b[0m\n",
      "\u001b[34mCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\u001b[0m\n",
      "\u001b[34mCollecting attrs>=18.1.0\n",
      "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.6.8-cp36-cp36m-manylinux2010_x86_64.whl (660 kB)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers==0.7.0\n",
      "  Downloading tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading dataclasses-0.7-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.5-py3-none-any.whl (351 kB)\u001b[0m\n",
      "\u001b[34mCollecting pygments\n",
      "  Downloading Pygments-2.6.1-py3-none-any.whl (914 kB)\u001b[0m\n",
      "\u001b[34mCollecting traitlets>=4.2\n",
      "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting pexpect; sys_platform != \"win32\"\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain->-r requirements.txt (line 1)) (46.1.3)\u001b[0m\n",
      "\u001b[34mCollecting jedi>=0.10\n",
      "  Downloading jedi-0.17.0-py2.py3-none-any.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (0.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (2.10.0)\u001b[0m\n",
      "\u001b[34mCollecting keras-pos-embd>=0.11.0\n",
      "  Downloading keras-pos-embd-0.11.0.tar.gz (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras-multi-head>=0.27.0\n",
      "  Downloading keras-multi-head-0.27.0.tar.gz (14 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras-layer-normalization>=0.14.0\n",
      "  Downloading keras-layer-normalization-0.14.0.tar.gz (4.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras-position-wise-feed-forward>=0.6.0\n",
      "  Downloading keras-position-wise-feed-forward-0.6.0.tar.gz (4.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras-embed-sim>=0.7.0\n",
      "  Downloading keras-embed-sim-0.7.0.tar.gz (4.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh->ktrain->-r requirements.txt (line 1)) (1.1.1)\u001b[0m\n",
      "\u001b[34mCollecting googleapis-common-protos\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.11.0->ktrain->-r requirements.txt (line 1)) (7.1.1)\u001b[0m\n",
      "\u001b[34mCollecting wcwidth\n",
      "  Downloading wcwidth-0.2.4-py2.py3-none-any.whl (30 kB)\u001b[0m\n",
      "\u001b[34mCollecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\u001b[0m\n",
      "\u001b[34mCollecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mCollecting parso>=0.7.0\n",
      "  Downloading parso-0.7.0-py2.py3-none-any.whl (100 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (4.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mCollecting keras-self-attention==0.46.0\n",
      "  Downloading keras-self-attention-0.46.0.tar.gz (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: ktrain, keras-bert, langdetect, jieba, bokeh, seqeval, syntok, keras-transformer, tornado, promise, dill, future, sacremoses, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for ktrain (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for ktrain (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m  Created wheel for ktrain: filename=ktrain-0.16.3-py3-none-any.whl size=25246181 sha256=d699d44c12e75895f8407f7d41ad0951e42656d889179975538dc7246bf9b14e\n",
      "  Stored in directory: /root/.cache/pip/wheels/aa/f1/85/933e438f6e33f1c1537dcf10ef119ace0337003852dad4f0d7\n",
      "  Building wheel for keras-bert (setup.py): started\n",
      "  Building wheel for keras-bert (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.84.0-py3-none-any.whl size=36139 sha256=8968839f635bf9da9a3ff06c6570c4a4484635ad920e2a103dd35745dc9a73b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/fa/43/d34d5e0cd8f3e93fa84c46990b5e233c6301cc9e0a10b7a0a0\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993191 sha256=3bcee0b106160f1700b84519be11c3287b45b17e6a8123e96308846de35ce7e9\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/88/5d/b239dc55d773b01fdd2059606b1a8f4b64548848b8f6e381c3\n",
      "  Building wheel for jieba (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=f811282ee20b921500d15c2be3a4a07c6796d2af8f50925e2350a5df8df6aaa5\n",
      "  Stored in directory: /root/.cache/pip/wheels/17/a7/8b/a7e03881534e78558920ac68aaeca05180c0e2c3d11c4fce3b\n",
      "  Building wheel for bokeh (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for bokeh (setup.py): finished with status 'done'\n",
      "  Created wheel for bokeh: filename=bokeh-2.0.2-py3-none-any.whl size=9072535 sha256=603e633764ae04bd9a79bd7e2a054f6bcd277bb1464c3ad16c21e1134c452fc1\n",
      "  Stored in directory: /root/.cache/pip/wheels/b0/68/c1/6b9042ddb66b14320f3a38df7bdcb38c4b411be9daae9df900\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7423 sha256=affd1f9a8f2dcee193f33133ff8637a204efa8a8b93d7729ee0408ed0016f2c3\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/1b/a6/a808a7e4d1f7584e42f5e279664cd48bf24ed8392218ce6be4\n",
      "  Building wheel for syntok (setup.py): started\n",
      "  Building wheel for syntok (setup.py): finished with status 'done'\n",
      "  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20916 sha256=a8008da82f8bf1a1af358bacdbaa42d5c8a0f9338640c1cebece9334142aa706\n",
      "  Stored in directory: /root/.cache/pip/wheels/c8/38/c7/e7ecfda67c818d8a78e91bcefd387f842a9be4f3232ed6baba\n",
      "  Building wheel for keras-transformer (setup.py): started\n",
      "  Building wheel for keras-transformer (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.37.0-py3-none-any.whl size=12941 sha256=22fac30d8501798f721f0c9bed1f0c59b9cb7b599c53034ca145f7274f7b3db0\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/b7/55/e0f95bc7333ed1ea83b9e5e7d864967824d5cdd25fa2c6f971\n",
      "  Building wheel for tornado (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for tornado (setup.py): finished with status 'done'\n",
      "  Created wheel for tornado: filename=tornado-6.0.4-cp36-cp36m-linux_x86_64.whl size=427625 sha256=f581cd063193113f2715cccc79eb4a94ace36ce037261fdecb75b7adc7e936eb\n",
      "  Stored in directory: /root/.cache/pip/wheels/37/a7/db/2d592e44029ef817f3ef63ea991db34191cebaef087a96f505\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21495 sha256=94d97b4a627658a6c07fb1ccee81d3e03ccdeda700020a29574210ac3e96f689\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/9a/1d/3f1afbbb5122d0410547bf9eb50955f4a7a98e53a6d8b99bd1\n",
      "  Building wheel for dill (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=658d414b5640ebb99934c58b34eb76bc13a57a6729e604889602504f65c2dced\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=f04b39e733d0933365b4689e035b0b5ed75a38444e6f5201ca538adcca4201fa\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=a999234f22fe25b379c3a09cd3f01d3a3c174190a31cdb31509dd3ac0ea420ea\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "  Building wheel for keras-pos-embd (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for keras-pos-embd (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-py3-none-any.whl size=7553 sha256=f7a7f5c5b7c14775afc4f90bdbc6ed8f377d6559660a3ddc7dabbe162a2db637\n",
      "  Stored in directory: /root/.cache/pip/wheels/13/b1/3b/13b632f78162148b123cddad1e0e3786df45ec37cac86dd998\n",
      "  Building wheel for keras-multi-head (setup.py): started\n",
      "  Building wheel for keras-multi-head (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-py3-none-any.whl size=15613 sha256=c264cc72caeb716208063bc264a3f17a303c7261618ec31f1b86b0847a2aedec\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/62/ae/d83210a242076c1841896a80b101e9b94f6dff931457150bf4\n",
      "  Building wheel for keras-layer-normalization (setup.py): started\n",
      "  Building wheel for keras-layer-normalization (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-py3-none-any.whl size=5267 sha256=837f9926df227f46fe62997256f156ac8cb88cf025faddc83c476cc9ab250f4c\n",
      "  Stored in directory: /root/.cache/pip/wheels/60/1a/38/858ffe627cf272dc54d9863d6c5ec993f00fd28d33f7f169f8\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): started\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-py3-none-any.whl size=5623 sha256=4ef017d92298c1e71ecab60b5494a3bd90c01f14dacb26cc1b1f0981d1a8bbea\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/25/c7/5a4c25eabcddaa3f108a9fe5ad8f0ad94e6566f25c391ea4f6\n",
      "  Building wheel for keras-embed-sim (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for keras-embed-sim (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-py3-none-any.whl size=4674 sha256=77c087b1039482b249fb55e76354644f6c44365e309e1ef1b019cfceef95f5f2\n",
      "  Stored in directory: /root/.cache/pip/wheels/f3/16/a7/275994b075e49c199afced51712534a142429c90cd92a19241\n",
      "  Building wheel for keras-self-attention (setup.py): started\n",
      "  Building wheel for keras-self-attention (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-py3-none-any.whl size=17278 sha256=5e80c7330bf3fe3850e9dba7712e9f50d9a1e845c1953b3be4eeef7e37137691\n",
      "  Stored in directory: /root/.cache/pip/wheels/ec/1c/45/1d2f27e87b5dc43e41ebfa437a231a2f7cf601db35c87b2637\u001b[0m\n",
      "\u001b[34mSuccessfully built ktrain keras-bert langdetect jieba bokeh seqeval syntok keras-transformer tornado promise dill future sacremoses keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tensorflow, scikit-learn, kiwisolver, cycler, matplotlib, fastprogress, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, jieba, cchardet, decorator, networkx, tornado, typing-extensions, bokeh, seqeval, googleapis-common-protos, tensorflow-metadata, promise, tqdm, dill, future, attrs, tensorflow-datasets, regex, filelock, sentencepiece, sacremoses, tokenizers, dataclasses, transformers, backcall, wcwidth, prompt-toolkit, pygments, ipython-genutils, traitlets, pickleshare, ptyprocess, pexpect, parso, jedi, ipython, syntok, whoosh, ktrain\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22\u001b[0m\n",
      "\u001b[34m    Uninstalling scikit-learn-0.22:\n",
      "      Successfully uninstalled scikit-learn-0.22\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-19.3.0 backcall-0.2.0 bokeh-2.0.2 cchardet-2.1.5 cycler-0.10.0 dataclasses-0.7 decorator-4.4.2 dill-0.3.1.1 fastprogress-0.2.3 filelock-3.0.12 future-0.18.2 googleapis-common-protos-1.52.0 ipython-7.15.0 ipython-genutils-0.2.0 jedi-0.17.0 jieba-0.42.1 keras-bert-0.84.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.37.0 kiwisolver-1.2.0 ktrain-0.16.3 langdetect-1.0.8 matplotlib-3.2.1 networkx-2.4 parso-0.7.0 pexpect-4.8.0 pickleshare-0.7.5 promise-2.3 prompt-toolkit-3.0.5 ptyprocess-0.6.0 pygments-2.6.1 regex-2020.6.8 sacremoses-0.0.43 scikit-learn-0.21.3 sentencepiece-0.1.91 seqeval-0.0.12 syntok-1.3.1 tensorflow-2.1.0 tensorflow-datasets-3.1.0 tensorflow-metadata-0.22.2 tokenizers-0.7.0 tornado-6.0.4 tqdm-4.46.1 traitlets-4.3.3 transformers-2.11.0 typing-extensions-3.7.4.2 wcwidth-0.2.4 whoosh-2.7.4\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 61, in <module>\n",
      "    model = text.text_classifier(args.model_name, train_data=trn, preproc=preproc)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ktrain/text/models.py\", line 470, in text_classifier\n",
      "    multilabel=multilabel, classification=True, metrics=metrics, verbose=verbose)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ktrain/text/models.py\", line 119, in _text_model\n",
      "    num_classes = U.nclasses_from_data(train_data)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ktrain/utils.py\", line 249, in nclasses_from_data\n",
      "    if isinstance(data, Dataset): return data.nclasses()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ktrain/text/preprocessor.py\", line 1332, in nclasses\n",
      "    return self.y.shape[1]\u001b[0m\n",
      "\u001b[34mIndexError: tuple index out of range\u001b[0m\n",
      "\u001b[34mGenerated image \u001b[0m\n",
      "\u001b[34m2020-06-13 05:46:30,292 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2020-06-13 05:46:30,292 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-06-13 05:46:48 Uploading - Uploading generated training model\n",
      "2020-06-13 05:46:48 Completed - Training job completed\n",
      "Training seconds: 182\n",
      "Billable seconds: 182\n"
     ]
    }
   ],
   "source": [
    "local_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
